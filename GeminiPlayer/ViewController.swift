//
//  ViewController.swift
//  GeminiPlayer
//
//  Created by zc on 5/21/23.
//

import UIKit
import Accelerate
//import MetalKit
import CoreGraphics


class ViewController: UIViewController {
    let imageView = UIImageView()

    
    override func viewDidLoad() {
        super.viewDidLoad()
        

        
        let version = String(cString: av_version_info())
        let config = String(cString: avcodec_configuration())
        let license = String(cString: avcodec_license())
        print("FFmpeg version: \(version)")
        let label = UILabel()
        label.numberOfLines = 0
        label.frame = self.view.bounds
        label.textAlignment = .center
        label.text = version + "\n" + config + "\n" + license
        self.view.addSubview(label)
        
        imageView.frame = CGRect(x: 0, y: 88, width: view.frame.width, height: 160)
        self.view.addSubview(imageView)
        imageView.backgroundColor = .black
        if let filePath = Bundle.main.path(forResource: "bbb_sunflower_1080p_30fps_normal_10s", ofType: "mp4") {
            DispatchQueue.global().async {
                av_log_set_level(AV_LOG_DEBUG)
                avformat_network_init()
                print("Video file path: \(filePath)")
                self.open(file: filePath)
            }

        } else {
            print("Video file not found")
        }
    }
    
    
    func open(file path: String?) {
        guard path != nil else {
            return
        }
        // åˆ†é…ä¸€ä¸ªAVFormatContext
        var avFormatContext = avformat_alloc_context()
        
        ///1ã€ä¸Šä¸‹æ–‡
        ///2ã€è§†é¢‘URL
        ///3ã€æ–‡ä»¶æ ¼å¼ã€‚å¦‚æœä¸ºç©ºè‡ªåŠ¨æ¢æµ‹æ ¼å¼
        ///4ã€ç‰¹å®šé€‰é¡¹å­—å…¸ ğŸŒ±
        if avformat_open_input(&avFormatContext, path, nil, nil) != 0 {
            print("æ— æ³•æ‰“å¼€æ–‡ä»¶")
            return
        }
        
        // è·å–æµä¿¡æ¯
        if avformat_find_stream_info(avFormatContext, nil) < 0 {
            print("æ— æ³•æ‰¾åˆ°æµä¿¡æ¯")
            return
        }
        
        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªè§†é¢‘æµ
        var videoStream = -1
        for i in 0..<(avFormatContext?.pointee.nb_streams ?? 0) {
            if avFormatContext?.pointee.streams[Int(i)]?.pointee.codecpar.pointee.codec_type == AVMEDIA_TYPE_VIDEO {
                videoStream = Int(i)
                break
            }
        }
        
        if videoStream == -1 {
            print("æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æµ")
            return
        }
        
        // è·å–è§†é¢‘æµçš„ç¼–è§£ç å™¨å‚æ•°
        let pCodecPar = avFormatContext?.pointee.streams[videoStream]?.pointee.codecpar
        
        // æ ¹æ®ç¼–ç å™¨æ‰¾åˆ°è§†é¢‘æµçš„è§£ç å™¨
        let pCodec = avcodec_find_decoder(pCodecPar?.pointee.codec_id ?? AV_CODEC_ID_NONE)
        
        if pCodec == nil {
            print("ä¸æ”¯æŒçš„ç¼–è§£ç å™¨ï¼")
            return
        }
        
        // ä¸ºä¸ç‰¹å®šç¼–è§£ç å™¨ç›¸å…³è”çš„ AVCodecContext åˆ†é…å†…å­˜
        var pCodecCtx = avcodec_alloc_context3(pCodec)
        if pCodecCtx == nil {
            print("æ— æ³•åˆ†é…ç¼–è§£ç å™¨ä¸Šä¸‹æ–‡")
            return
        }
        
        ///å°†AVCodecParametersç»“æ„çš„å€¼å¤åˆ¶åˆ°AVCodecContextç»“æ„ã€‚
        ///AVCodecParametersåŒ…å«æœ‰å…³åª’ä½“æµï¼ˆå¦‚éŸ³é¢‘æˆ–è§†é¢‘ï¼‰çš„ç¼–è§£ç å™¨çš„å‚æ•°ã€‚
        ///è¿™äº›å‚æ•°åŒ…æ‹¬ç¼–è§£ç å™¨ç±»å‹ã€ç¼–è§£ç å™¨IDã€æ¯”ç‰¹ç‡ã€å¸§ç‡ã€é‡‡æ ·ç‡ã€åƒç´ æ ¼å¼ã€å£°é“å¸ƒå±€ç­‰ç­‰ã€‚
        if avcodec_parameters_to_context(pCodecCtx, pCodecPar) < 0 {
            print("æ— æ³•å¤åˆ¶ç¼–è§£ç å™¨å‚æ•°")
            return
        }
        
        // æ‰“å¼€ç¼–è§£ç å™¨
        if avcodec_open2(pCodecCtx, pCodec, nil) < 0 {
            print("æ— æ³•æ‰“å¼€ç¼–è§£ç å™¨")
            return
        }

        // ä»»åŠ¡æ˜¯ä¸ºAVPacketç»“æ„åˆ†é…å†…å­˜
        let packet = av_packet_alloc()
        
        
        // ä¸ºAVFrameç»“æ„åˆ†é…å†…å­˜
        var pFrame = av_frame_alloc()

        // å¾ªç¯è¯»å–ä¸‹ä¸€å¸§
        while av_read_frame(avFormatContext, packet) >= 0 {
            // è¿™ä¸ªåŒ…æ˜¯è§†é¢‘æµçš„å—ï¼Ÿ
            if (packet?.pointee.stream_index ?? 0) == videoStream {
                // å°†åŒ…å«å‹ç¼©æ•°æ®çš„ AVPacket å‘é€åˆ°è§£ç å™¨è¿›è¡Œè§£ç 
                if avcodec_send_packet(pCodecCtx, packet) < 0 {
                    print("å‘é€åŒ…å¤±è´¥")
                    continue
                }
                
                // ä½œç”¨æ˜¯ä»ç¼–è§£ç å™¨ä¸­æ¥æ”¶è§£ç åçš„æ•°æ®å¸§
                while avcodec_receive_frame(pCodecCtx, pFrame) == 0 {
                    
                    let width = Int(pFrame?.pointee.width ?? 0)
                    let height = Int(pFrame?.pointee.height ?? 0)
                    // è¡Œè·¨åº¦ å°±æ˜¯è§†é¢‘çš„å®½åº¦
                    let stride = Int(pFrame?.pointee.linesize.0 ?? 0)
                    
                    
                    
                    
                    // å£°æ˜äº†ä¸€ä¸ªå¯é€‰çš„CVPixelBufferå˜é‡ã€‚è¿™ä¸ªå˜é‡å°†è¢«ç”¨äºå­˜å‚¨åˆ›å»ºçš„CVPixelBuffer
                    var pixelBuffer: CVPixelBuffer?
                    
                    let attrs = [
                        kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue, //è¿™ä¸ªé”®å€¼å¯¹è¡¨ç¤ºåˆ›å»ºçš„CVPixelBufferåº”è¯¥ä¸CGImageå…¼å®¹ã€‚CGImageæ˜¯Core Graphicsæ¡†æ¶ä¸­çš„ä¸€ä¸ªæ•°æ®ç±»å‹ï¼Œç”¨äºè¡¨ç¤ºä½å›¾å›¾åƒã€‚å¦‚æœè®¾ç½®äº†è¿™ä¸ªå±æ€§ï¼Œä½ å¯ä»¥å°†CVPixelBufferç›´æ¥è½¬æ¢ä¸ºCGImageï¼Œæˆ–è€…ä»CGImageåˆ›å»ºCVPixelBuffer
                        kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue //è¿™ä¸ªé”®å€¼å¯¹è¡¨ç¤ºåˆ›å»ºçš„CVPixelBufferåº”è¯¥ä¸CGBitmapContextå…¼å®¹ã€‚CGBitmapContextæ˜¯Core Graphicsæ¡†æ¶ä¸­çš„ä¸€ä¸ªæ•°æ®ç±»å‹ï¼Œç”¨äºå¤„ç†ä½å›¾å›¾åƒçš„ä¸Šä¸‹æ–‡ã€‚å¦‚æœè®¾ç½®äº†è¿™ä¸ªå±æ€§ï¼Œä½ å¯ä»¥å°†CVPixelBufferç›´æ¥ç”¨äºCGBitmapContextï¼Œæˆ–è€…ä»CGBitmapContextåˆ›å»ºCVPixelBufferã€‚
                    ]
                    
                    let status = CVPixelBufferCreateWithBytes(
                        nil, // åˆ†é…åƒç´ ç¼“å†²åŒºå†…å­˜çš„å›è°ƒï¼Œè¿™é‡Œæˆ‘ä»¬è®©ç³»ç»Ÿè‡ªåŠ¨åˆ†é…ï¼Œæ‰€ä»¥ä¼ é€’nil
                        width, // åƒç´ ç¼“å†²åŒºçš„å®½åº¦ï¼Œå¯¹åº”äºè§†é¢‘å¸§çš„å®½åº¦
                        height, // åƒç´ ç¼“å†²åŒºçš„é«˜åº¦ï¼Œå¯¹åº”äºè§†é¢‘å¸§çš„é«˜åº¦
                        kCVPixelFormatType_420YpCbCr8BiPlanarVideoRange, // åƒç´ ç¼“å†²åŒºçš„åƒç´ æ ¼å¼ï¼Œè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨YUV420Pæ ¼å¼ï¼Œå¯¹åº”äºæˆ‘ä»¬ä»FFmpegè§£ç çš„è§†é¢‘å¸§çš„æ ¼å¼
                        pFrame!.pointee.data.0!, // åƒç´ æ•°æ®çš„æŒ‡é’ˆï¼Œè¿™ä¸ªæ•°æ®æ¥è‡ªäºæˆ‘ä»¬ä»FFmpegè§£ç çš„è§†é¢‘å¸§
                        stride, // åƒç´ ç¼“å†²åŒºçš„è¡Œè·¨åº¦ï¼Œå¯¹åº”äºè§†é¢‘å¸§çš„è¡Œè·¨åº¦
                        nil, // é‡Šæ”¾åƒç´ ç¼“å†²åŒºå†…å­˜çš„å›è°ƒï¼Œè¿™é‡Œæˆ‘ä»¬è®©ç³»ç»Ÿè‡ªåŠ¨é‡Šæ”¾ï¼Œæ‰€ä»¥ä¼ é€’nil
                        nil, // é¢å¤–çš„åƒç´ ç¼“å†²åŒºå±æ€§ï¼Œè¿™é‡Œæˆ‘ä»¬ä¸éœ€è¦é¢å¤–çš„å±æ€§ï¼Œæ‰€ä»¥ä¼ é€’nil
                        attrs as CFDictionary, // åƒç´ ç¼“å†²åŒºçš„å±æ€§ï¼Œæˆ‘ä»¬ä¹‹å‰åˆ›å»ºäº†è¿™ä¸ªå­—å…¸ï¼Œä»¥ç¡®ä¿åƒç´ ç¼“å†²åŒºä¸CGImageå’ŒCGBitmapContextå…¼å®¹
                        &pixelBuffer // è¿™æ˜¯ä¸€ä¸ªæŒ‡å‘CVPixelBufferå˜é‡çš„æŒ‡é’ˆï¼ŒCVPixelBufferCreateWithByteså‡½æ•°å°†åˆ›å»ºçš„CVPixelBufferå­˜å‚¨åœ¨è¿™ä¸ªå˜é‡ä¸­
                    )
                    
                    
                    if status != kCVReturnSuccess {
                        print("åˆ›å»ºåƒç´ ç¼“å†²åŒºé”™è¯¯")
                        return
                    }
                    
                    let uiImage =  UIImage(pixelBuffer: pixelBuffer!)!
                    let image = convertYUV420ToRGB8888(yuvImage: uiImage)
                    DispatchQueue.main.async { [self] in
                        self.imageView.image = image//UIImage(named: "output.jpg")
                    }
    
                    
//                   let uiImage =  pixelBufferToImage(pixelBuffer: pixelBuffer!)
                    
//                    let ciImage = CIImage(cvPixelBuffer: pixelBuffer!)
                    
//                    let uiImage = UIImage(ciImage: ciImage)
//                    DispatchQueue.main.async {
//                        self.imageView.image = uiImage
//                    }
                }
            }
            
            // é‡Šæ”¾ç”±av_read_frameåˆ†é…çš„åŒ…
            av_packet_unref(packet)
        }
        
        // é‡Šæ”¾å¸§
        av_frame_free(&pFrame)
        
        // å…³é—­ç¼–è§£ç å™¨
        avcodec_free_context(&pCodecCtx)
        
        // å…³é—­è§†é¢‘æ–‡ä»¶
        avformat_close_input(&avFormatContext)
        
        
        
    }
    
    func saveImageToSandbox(image: UIImage, filename: String) {
        // è·å–æ²™ç›’çš„Documentsç›®å½•
        let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let fileURL = documentsDirectory.appendingPathComponent(filename)

        // å°†UIImageè½¬æ¢ä¸ºPNGæ•°æ®
        if let data = image.pngData() {
            // å°†æ•°æ®å†™å…¥åˆ°æ–‡ä»¶
            do {
                try data.write(to: fileURL)
                print("Image saved to \(fileURL)")
            } catch {
                print("Error saving image: \(error)")
            }
        }
    }
    


}


import VideoToolbox

extension UIImage {
    public convenience init?(pixelBuffer: CVPixelBuffer) {
        var cgImage: CGImage?
        VTCreateCGImageFromCVPixelBuffer(pixelBuffer, options: nil, imageOut: &cgImage)

        guard let cgImage = cgImage else {
            return nil
        }

        self.init(cgImage: cgImage)
    }
}


func convertYUV420ToRGB8888(yuvImage: UIImage) -> UIImage? {
    guard let cgImage = yuvImage.cgImage else { return nil }
    let colorSpace = CGColorSpaceCreateDeviceRGB()
    
    let context = CGContext(data: nil,
                            width: cgImage.width,
                            height: cgImage.height,
                            bitsPerComponent: 8,
                            bytesPerRow: cgImage.width * 4,
                            space: colorSpace,
                            bitmapInfo: CGBitmapInfo.byteOrder32Big.rawValue | CGImageAlphaInfo.premultipliedLast.rawValue)
    
    guard let bitmapData = context?.data else { return nil }
    
    let yPlane: UnsafeMutablePointer<UInt8> = bitmapData.assumingMemoryBound(to: UInt8.self)
    let uPlane: UnsafeMutablePointer<UInt8> = yPlane + (cgImage.width * cgImage.height)
    let vPlane: UnsafeMutablePointer<UInt8> = uPlane + ((cgImage.width * cgImage.height) / 4)
    
    for y in 0..<cgImage.height {
        for x in 0..<cgImage.width {
            let yPixel = yPlane[y * cgImage.width + x]
            let uPixel = uPlane[(y/2) * (cgImage.width/2) + (x/2)]
            let vPixel = vPlane[(y/2) * (cgImage.width/2) + (x/2)]
            
            let rCalc = 1.370705 * Double((Int(vPixel) - 128))
            let rPixel = max(0, min(255, Int(Double(yPixel)) + Int(rCalc)))
            
            let gCalc1 = 0.698001 * Double((Int(vPixel) - 128))
            let gCalc2 = 0.337633 * Double((Int(uPixel) - 128))
            let gPixel = max(0, min(255, Double(Int(Double(yPixel))) - gCalc1 - gCalc2))
            
            let bCalc = 1.732446 * Double((Int(uPixel) - 128))
            let bPixel = max(0, min(255, Int(Double(yPixel)) + Int(bCalc)))
            
            context?.setFillColor(red: CGFloat(rPixel)/255, green: CGFloat(gPixel)/255, blue: CGFloat(bPixel)/255, alpha: 1)
            context?.fill(CGRect(x: x, y: y, width: 1, height: 1))
        }
    }
    
    return context?.makeImage().flatMap { UIImage(cgImage: $0) }
}
