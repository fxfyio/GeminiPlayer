//
//  ViewController.swift
//  GeminiPlayer
//
//  Created by zc on 5/21/23.
//

import UIKit
import Accelerate
//import MetalKit
import CoreGraphics
import AVFoundation


class ViewController: UIViewController {
    let playerView = UIView()

    let videoLayer = AVSampleBufferDisplayLayer()

    override func viewDidLoad() {
        super.viewDidLoad()
        
        videoLayer.frame = CGRect(x: 0, y: 0, width: view.frame.width, height: 200)
        videoLayer.videoGravity = .resizeAspect
        videoLayer.backgroundColor = UIColor.red.cgColor
        playerView.layer.addSublayer(videoLayer)

        videoLayer.addObserver(self, forKeyPath: "status", options: [.new], context: nil)
        videoLayer.addObserver(self, forKeyPath: "error", options: [.new], context: nil)

        let version = String(cString: av_version_info())
        let config = String(cString: avcodec_configuration())
        let license = String(cString: avcodec_license())
        print("FFmpeg version: \(version)")
        let label = UILabel()
        label.numberOfLines = 0
        label.frame = self.view.bounds
        label.textAlignment = .center
        label.text = version + "\n" + config + "\n" + license
        self.view.addSubview(label)
        
        playerView.frame = CGRect(x: 0, y: 88, width: view.frame.width, height: 200)
        self.view.addSubview(playerView)
        playerView.backgroundColor = .black
        if let filePath = Bundle.main.path(forResource: "bbb_sunflower_1080p_30fps_normal", ofType: "mp4") {
            DispatchQueue.global().async { [weak self] in
                guard let self = self else {
                    return
                }
                av_log_set_level(AV_LOG_DEBUG)
                avformat_network_init()
                print("Video file path: \(filePath)")
                self.open(file: filePath)
            }

        } else {
            print("Video file not found")
        }
    }
    
    override func observeValue(forKeyPath keyPath: String?, of object: Any?, change: [NSKeyValueChangeKey : Any]?, context: UnsafeMutableRawPointer?) {
        if keyPath == "status" {
            if let status = change?[.newKey] as? Int {
                switch status {
                case 0:
                    print("The status of the player item is unknown.")
                case 1:
                    print("The player item is ready to play.")
                case 2:
                    print("The player item failed. See the error property for more information.")
                default:
                    break
                }
            }
        } else if keyPath == "error" {
            print("xxx")
        }
    }

    
    func open(file path: String?) {
        guard path != nil else {
            return
        }
        // åˆ†é…ä¸€ä¸ªAVFormatContext
        var avFormatContext = avformat_alloc_context()
        
        ///1ã€ä¸Šä¸‹æ–‡
        ///2ã€è§†é¢‘URL
        ///3ã€æ–‡ä»¶æ ¼å¼ã€‚å¦‚æœä¸ºç©ºè‡ªåŠ¨æ¢æµ‹æ ¼å¼
        ///4ã€ç‰¹å®šé€‰é¡¹å­—å…¸ ğŸŒ±
        if avformat_open_input(&avFormatContext, path, nil, nil) != 0 {
            print("æ— æ³•æ‰“å¼€æ–‡ä»¶")
            return
        }
        
        // è·å–æµä¿¡æ¯
        if avformat_find_stream_info(avFormatContext, nil) < 0 {
            print("æ— æ³•æ‰¾åˆ°æµä¿¡æ¯")
            return
        }
        
        // æ‰¾åˆ°ç¬¬ä¸€ä¸ªè§†é¢‘æµ
        var videoStream = -1
        for i in 0..<(avFormatContext?.pointee.nb_streams ?? 0) {
            if avFormatContext?.pointee.streams[Int(i)]?.pointee.codecpar.pointee.codec_type == AVMEDIA_TYPE_VIDEO {
                videoStream = Int(i)
                break
            }
        }
        
        if videoStream == -1 {
            print("æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æµ")
            return
        }
        
        // è·å–è§†é¢‘æµçš„ç¼–è§£ç å™¨å‚æ•°
        let pCodecPar = avFormatContext?.pointee.streams[videoStream]?.pointee.codecpar
        
        // æ ¹æ®ç¼–ç å™¨æ‰¾åˆ°è§†é¢‘æµçš„è§£ç å™¨
        let pCodec = avcodec_find_decoder(pCodecPar?.pointee.codec_id ?? AV_CODEC_ID_NONE)
        
        if pCodec == nil {
            print("ä¸æ”¯æŒçš„ç¼–è§£ç å™¨ï¼")
            return
        }
        
        // ä¸ºä¸ç‰¹å®šç¼–è§£ç å™¨ç›¸å…³è”çš„ AVCodecContext åˆ†é…å†…å­˜
        var pCodecCtx = avcodec_alloc_context3(pCodec)
        if pCodecCtx == nil {
            print("æ— æ³•åˆ†é…ç¼–è§£ç å™¨ä¸Šä¸‹æ–‡")
            return
        }
        
        ///å°†AVCodecParametersç»“æ„çš„å€¼å¤åˆ¶åˆ°AVCodecContextç»“æ„ã€‚
        ///AVCodecParametersåŒ…å«æœ‰å…³åª’ä½“æµï¼ˆå¦‚éŸ³é¢‘æˆ–è§†é¢‘ï¼‰çš„ç¼–è§£ç å™¨çš„å‚æ•°ã€‚
        ///è¿™äº›å‚æ•°åŒ…æ‹¬ç¼–è§£ç å™¨ç±»å‹ã€ç¼–è§£ç å™¨IDã€æ¯”ç‰¹ç‡ã€å¸§ç‡ã€é‡‡æ ·ç‡ã€åƒç´ æ ¼å¼ã€å£°é“å¸ƒå±€ç­‰ç­‰ã€‚
        if avcodec_parameters_to_context(pCodecCtx, pCodecPar) < 0 {
            print("æ— æ³•å¤åˆ¶ç¼–è§£ç å™¨å‚æ•°")
            return
        }
        
        // æ‰“å¼€ç¼–è§£ç å™¨
        if avcodec_open2(pCodecCtx, pCodec, nil) < 0 {
            print("æ— æ³•æ‰“å¼€ç¼–è§£ç å™¨")
            return
        }

        // ä»»åŠ¡æ˜¯ä¸ºAVPacketç»“æ„åˆ†é…å†…å­˜
        let packet = av_packet_alloc()
        
        
        // ä¸ºAVFrameç»“æ„åˆ†é…å†…å­˜
        var pFrame = av_frame_alloc()

        // å¾ªç¯è¯»å–ä¸‹ä¸€å¸§
        while av_read_frame(avFormatContext, packet) >= 0 {
            // è¿™ä¸ªåŒ…æ˜¯è§†é¢‘æµçš„å—ï¼Ÿ
            if (packet?.pointee.stream_index ?? 0) == videoStream {
                // å°†åŒ…å«å‹ç¼©æ•°æ®çš„ AVPacket å‘é€åˆ°è§£ç å™¨è¿›è¡Œè§£ç 
                if avcodec_send_packet(pCodecCtx, packet) < 0 {
                    print("å‘é€åŒ…å¤±è´¥")
                    continue
                }
                
                // ä½œç”¨æ˜¯ä»ç¼–è§£ç å™¨ä¸­æ¥æ”¶è§£ç åçš„æ•°æ®å¸§
                while avcodec_receive_frame(pCodecCtx, pFrame) == 0 {
                    
                    if let pointer = pFrame {
                        
                        // è·å– AVFrame çš„åƒç´ æ•°æ®å’Œè¡Œå¤§å°
                        // è·å– AVFrame çš„åƒç´ æ•°æ®å’Œè¡Œå¤§å°
                        let frameData: [UnsafePointer<UInt8>?] = [
                            UnsafePointer(pointer.pointee.data.0!),
                            UnsafePointer(pointer.pointee.data.1!),
                            UnsafePointer(pointer.pointee.data.2!)
                        ]


                        let frameLinesize = [
                            Int32(pointer.pointee.linesize.0),
                            Int32(pointer.pointee.linesize.1),
                            Int32(pointer.pointee.linesize.2)
                        ]


                        // åˆ›å»ºä¸€ä¸ª SwsContext æ¥è¿›è¡Œåƒç´ æ ¼å¼è½¬æ¢å’Œç¼©æ”¾
                        let swsContext = sws_getContext(
                            pCodecCtx!.pointee.width,
                            pCodecCtx!.pointee.height,
                            pCodecCtx!.pointee.pix_fmt,
                            pCodecCtx!.pointee.width,
                            pCodecCtx!.pointee.height,
                            AV_PIX_FMT_RGB24,
                            SWS_BILINEAR,
                            nil, nil, nil
                        )
                        
                        // åˆ›å»ºä¸€ä¸ª CVPixelBuffer æ¥ä¿å­˜è§£ç åçš„åƒç´ æ•°æ®
                        var pixelBuffer: CVPixelBuffer?
                        let attrs = [
                            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue,
                            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue
                        ] as CFDictionary
                        let status = CVPixelBufferCreate(kCFAllocatorDefault, Int(pCodecCtx!.pointee.width), Int(pCodecCtx!.pointee.height), kCVPixelFormatType_32ARGB, attrs, &pixelBuffer)
                        guard status == kCVReturnSuccess else {
                            print("Error: could not create CVPixelBuffer")
                            continue
                        }


                        // è·å– CVPixelBuffer çš„åƒç´ æ•°æ®å’Œè¡Œå¤§å°
                        CVPixelBufferLockBaseAddress(pixelBuffer!, CVPixelBufferLockFlags(rawValue: 0))
                        let pixelBufferBaseAddress = CVPixelBufferGetBaseAddress(pixelBuffer!)!.assumingMemoryBound(to: UInt8.self)
                        let pixelBufferBytesPerRow = CVPixelBufferGetBytesPerRow(pixelBuffer!)
                      
                        let frameDataBuffer = frameData.withUnsafeBufferPointer { UnsafePointer($0.baseAddress) }

                        // å°†åƒç´ æ•°æ®ä» AVFrame å¤åˆ¶åˆ° CVPixelBuffer
                        var dst: [UnsafeMutablePointer<UInt8>?] = [pixelBufferBaseAddress]
                        var dstStride = [Int32(pixelBufferBytesPerRow)]
                        sws_scale(
                            swsContext,
                            frameData,
                            frameLinesize,
                            0,
                            pCodecCtx!.pointee.height,
                            &dst,
                            &dstStride
                        )
                        
                        // åˆ›å»ºä¸€ä¸ª CMSampleBuffer
                        var sampleBuffer: CMSampleBuffer?
                        var timingInfo = CMSampleTimingInfo(duration: CMTime.invalid, presentationTimeStamp: CMTime.invalid, decodeTimeStamp: CMTime.invalid)
                        var formatDescription: CMVideoFormatDescription?
                        CMVideoFormatDescriptionCreateForImageBuffer(allocator: kCFAllocatorDefault, imageBuffer: pixelBuffer!, formatDescriptionOut: &formatDescription)
                        CMSampleBufferCreateForImageBuffer(allocator: kCFAllocatorDefault, imageBuffer: pixelBuffer!, dataReady: true, makeDataReadyCallback: nil, refcon: nil, formatDescription: formatDescription!, sampleTiming: &timingInfo, sampleBufferOut: &sampleBuffer)
                        
                        // å°† CMSampleBuffer æ·»åŠ åˆ° videoLayer
                        DispatchQueue.main.async {
                            if self.videoLayer.isReadyForMoreMediaData {
                                self.videoLayer.enqueue(sampleBuffer!)
                            }
                        }
                        
                    }
                    
                    
                }
            }
            
            // é‡Šæ”¾ç”±av_read_frameåˆ†é…çš„åŒ…
            av_packet_unref(packet)
        }
        
        // é‡Šæ”¾å¸§
        av_frame_free(&pFrame)
        
        // å…³é—­ç¼–è§£ç å™¨
        avcodec_free_context(&pCodecCtx)
        
        // å…³é—­è§†é¢‘æ–‡ä»¶
        avformat_close_input(&avFormatContext)
        
        
        
    }
    
    func saveImageToSandbox(image: UIImage, filename: String) {
        // è·å–æ²™ç›’çš„Documentsç›®å½•
        let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let fileURL = documentsDirectory.appendingPathComponent(filename)

        // å°†UIImageè½¬æ¢ä¸ºPNGæ•°æ®
        if let data = image.pngData() {
            // å°†æ•°æ®å†™å…¥åˆ°æ–‡ä»¶
            do {
                try data.write(to: fileURL)
                print("Image saved to \(fileURL)")
            } catch {
                print("Error saving image: \(error)")
            }
        }
    }
    


}


import VideoToolbox

extension UIImage {
    public convenience init?(pixelBuffer: CVPixelBuffer) {
        var cgImage: CGImage?
        VTCreateCGImageFromCVPixelBuffer(pixelBuffer, options: nil, imageOut: &cgImage)

        guard let cgImage = cgImage else {
            return nil
        }

        self.init(cgImage: cgImage)
    }
}


func convertYUV420ToRGB8888(yuvImage: UIImage) -> UIImage? {
    guard let cgImage = yuvImage.cgImage else { return nil }
    let colorSpace = CGColorSpaceCreateDeviceRGB()
    
    let context = CGContext(data: nil,
                            width: cgImage.width,
                            height: cgImage.height,
                            bitsPerComponent: 8,
                            bytesPerRow: cgImage.width * 4,
                            space: colorSpace,
                            bitmapInfo: CGBitmapInfo.byteOrder32Big.rawValue | CGImageAlphaInfo.premultipliedLast.rawValue)
    
    guard let bitmapData = context?.data else { return nil }
    
    let yPlane: UnsafeMutablePointer<UInt8> = bitmapData.assumingMemoryBound(to: UInt8.self)
    let uPlane: UnsafeMutablePointer<UInt8> = yPlane + (cgImage.width * cgImage.height)
    let vPlane: UnsafeMutablePointer<UInt8> = uPlane + ((cgImage.width * cgImage.height) / 4)
    
    for y in 0..<cgImage.height {
        for x in 0..<cgImage.width {
            let yPixel = yPlane[y * cgImage.width + x]
            let uPixel = uPlane[(y/2) * (cgImage.width/2) + (x/2)]
            let vPixel = vPlane[(y/2) * (cgImage.width/2) + (x/2)]
            
            let rCalc = 1.370705 * Double((Int(vPixel) - 128))
            let rPixel = max(0, min(255, Int(Double(yPixel)) + Int(rCalc)))
            
            let gCalc1 = 0.698001 * Double((Int(vPixel) - 128))
            let gCalc2 = 0.337633 * Double((Int(uPixel) - 128))
            let gPixel = max(0, min(255, Double(Int(Double(yPixel))) - gCalc1 - gCalc2))
            
            let bCalc = 1.732446 * Double((Int(uPixel) - 128))
            let bPixel = max(0, min(255, Int(Double(yPixel)) + Int(bCalc)))
            
            context?.setFillColor(red: CGFloat(rPixel)/255, green: CGFloat(gPixel)/255, blue: CGFloat(bPixel)/255, alpha: 1)
            context?.fill(CGRect(x: x, y: y, width: 1, height: 1))
        }
    }
    
    return context?.makeImage().flatMap { UIImage(cgImage: $0) }
}
